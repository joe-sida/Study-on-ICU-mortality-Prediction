{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\USER\\Downloads\\Researchs on Mortality Prediction in ICU\\Mortality Prediction in ICU\\train.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(r'C:\\Users\\USER\\Downloads\\Researchs on Mortality Prediction in ICU\\Mortality Prediction in ICU\\labels.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>58.897059</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>96.833333</td>\n",
       "      <td>113.411765</td>\n",
       "      <td>36.939130</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>151.560976</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>80.670588</td>\n",
       "      <td>7.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>199.5</td>\n",
       "      <td>44</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>125.687500</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>124.951220</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>56.700000</td>\n",
       "      <td>7.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>15.457627</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.223077</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>545.833333</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.880000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>62.131579</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ALP   ALT    AST  Age   Albumin        BUN  Bilirubin  Cholesterol  \\\n",
       "0   77.0  31.0   46.0   54  2.973333  10.500000        0.7        154.0   \n",
       "1   77.0  31.0   46.0   76  2.973333  18.333333        0.7        154.0   \n",
       "2  116.0  83.0  199.5   44  2.500000   4.666667        2.9        154.0   \n",
       "3  105.0  12.0   15.0   68  4.400000  17.666667        0.2        154.0   \n",
       "4   77.0  31.0   46.0   88  3.300000  35.000000        0.7        154.0   \n",
       "\n",
       "   Creatinine    DiasABP  ...   RespRate       SaO2      SysABP       Temp  \\\n",
       "0    0.750000  58.795833  ...  17.428571  97.250000  116.891892  37.357143   \n",
       "1    1.100000  58.897059  ...  19.000000  96.833333  113.411765  36.939130   \n",
       "2    0.333333  67.125000  ...  19.000000  95.000000  125.687500  37.800000   \n",
       "3    0.766667  58.795833  ...  15.457627  97.250000  116.891892  36.223077   \n",
       "4    1.000000  58.795833  ...  19.166667  97.250000  116.891892  36.880000   \n",
       "\n",
       "   TroponinI  TroponinT       Urine        WBC     Weight        pH  \n",
       "0        2.1       0.14  171.052632  10.300000  80.060976  7.387273  \n",
       "1        2.1       0.14  151.560976  11.266667  80.670588  7.395000  \n",
       "2        2.1       0.14  124.951220   4.700000  56.700000  7.495000  \n",
       "3        2.1       0.14  545.833333   9.400000  84.600000  7.387273  \n",
       "4        2.1       0.14   62.131579   4.300000  80.060976  7.387273  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot encoding\n",
    "temp  =[]\n",
    "for i in labels[\"In-hospital_death\"]:\n",
    "    if i == 0:\n",
    "        temp.append([1,0])\n",
    "    else:\n",
    "        temp.append([0,1])\n",
    "temp = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3445\n",
       "1     554\n",
       "Name: In-hospital_death, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"In-hospital_death\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 43)\n"
     ]
    }
   ],
   "source": [
    "new = pd.concat([df , labels] , axis = 1)\n",
    "print(new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new.drop('In-hospital_death', axis=1)\n",
    "y = new['In-hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new.drop(['Gender','Cholesterol','HCT','ICUType','Height'] , axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3999 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ALP    ALT    AST    Age  Albumin    BUN  Bilirubin  Cholesterol  \\\n",
       "0     False  False  False  False    False  False      False        False   \n",
       "1     False  False  False  False    False  False      False        False   \n",
       "2     False  False  False  False    False  False      False        False   \n",
       "3     False  False  False  False    False  False      False        False   \n",
       "4     False  False  False  False    False  False      False        False   \n",
       "...     ...    ...    ...    ...      ...    ...        ...          ...   \n",
       "3994  False  False  False  False    False  False      False        False   \n",
       "3995  False  False  False  False    False  False      False        False   \n",
       "3996  False  False  False  False    False  False      False        False   \n",
       "3997  False  False  False  False    False  False      False        False   \n",
       "3998  False  False  False  False    False  False      False        False   \n",
       "\n",
       "      Creatinine  DiasABP  ...   SaO2  SysABP   Temp  TroponinI  TroponinT  \\\n",
       "0          False    False  ...  False   False  False      False      False   \n",
       "1          False    False  ...  False   False  False      False      False   \n",
       "2          False    False  ...  False   False  False      False      False   \n",
       "3          False    False  ...  False   False  False      False      False   \n",
       "4          False    False  ...  False   False  False      False      False   \n",
       "...          ...      ...  ...    ...     ...    ...        ...        ...   \n",
       "3994       False    False  ...  False   False  False      False      False   \n",
       "3995       False    False  ...  False   False  False      False      False   \n",
       "3996       False    False  ...  False   False  False      False      False   \n",
       "3997       False    False  ...  False   False  False      False      False   \n",
       "3998       False    False  ...  False   False  False      False      False   \n",
       "\n",
       "      Urine    WBC  Weight     pH  In-hospital_death  \n",
       "0     False  False   False  False              False  \n",
       "1     False  False   False  False              False  \n",
       "2     False  False   False  False              False  \n",
       "3     False  False   False  False              False  \n",
       "4     False  False   False  False              False  \n",
       "...     ...    ...     ...    ...                ...  \n",
       "3994  False  False   False  False              False  \n",
       "3995  False  False   False  False              False  \n",
       "3996  False  False   False  False              False  \n",
       "3997  False  False   False  False              False  \n",
       "3998  False  False   False  False              False  \n",
       "\n",
       "[3999 rows x 43 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>58.897059</td>\n",
       "      <td>...</td>\n",
       "      <td>96.833333</td>\n",
       "      <td>113.411765</td>\n",
       "      <td>36.939130</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>151.560976</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>80.670588</td>\n",
       "      <td>7.395000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.00</td>\n",
       "      <td>199.500000</td>\n",
       "      <td>44</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>125.687500</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>124.951220</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>56.700000</td>\n",
       "      <td>7.495000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>68</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.223077</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>545.833333</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.880000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>62.131579</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>82.0</td>\n",
       "      <td>32.25</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>70</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>68.865385</td>\n",
       "      <td>...</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>117.230769</td>\n",
       "      <td>37.004762</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>50.769231</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.381429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>82.0</td>\n",
       "      <td>32.25</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>58.754774</td>\n",
       "      <td>...</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>117.820733</td>\n",
       "      <td>36.580000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>584.375000</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>166.400000</td>\n",
       "      <td>7.385000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>51.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>74.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>125.666667</td>\n",
       "      <td>37.792308</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>116.472222</td>\n",
       "      <td>11.066667</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>7.396667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>169.0</td>\n",
       "      <td>1971.00</td>\n",
       "      <td>1685.333333</td>\n",
       "      <td>37</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>89.250000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>145.0</td>\n",
       "      <td>9.650000</td>\n",
       "      <td>92.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>166.615385</td>\n",
       "      <td>38.418182</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>11.230769</td>\n",
       "      <td>13.025000</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>7.416000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>44.0</td>\n",
       "      <td>18.50</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>78</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>20.166667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>57.836957</td>\n",
       "      <td>...</td>\n",
       "      <td>97.466667</td>\n",
       "      <td>111.532609</td>\n",
       "      <td>36.381395</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>9.228571</td>\n",
       "      <td>87.838889</td>\n",
       "      <td>7.305600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3999 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ALP      ALT          AST  Age   Albumin        BUN  Bilirubin  \\\n",
       "0      77.0    31.00    46.000000   54  2.973333  10.500000   0.700000   \n",
       "1      77.0    31.00    46.000000   76  2.973333  18.333333   0.700000   \n",
       "2     116.0    83.00   199.500000   44  2.500000   4.666667   2.900000   \n",
       "3     105.0    12.00    15.000000   68  4.400000  17.666667   0.200000   \n",
       "4      77.0    31.00    46.000000   88  3.300000  35.000000   0.700000   \n",
       "...     ...      ...          ...  ...       ...        ...        ...   \n",
       "3994   82.0    32.25    49.000000   70  3.000000  16.000000   0.700000   \n",
       "3995   82.0    32.25    49.000000   25  3.000000   4.400000   0.700000   \n",
       "3996   51.0    20.00    20.000000   44  3.000000   7.750000   0.500000   \n",
       "3997  169.0  1971.00  1685.333333   37  3.100000  89.250000   0.733333   \n",
       "3998   44.0    18.50   126.000000   78  2.200000  20.166667   0.600000   \n",
       "\n",
       "      Cholesterol  Creatinine    DiasABP  ...       SaO2      SysABP  \\\n",
       "0           154.0    0.750000  58.795833  ...  97.250000  116.891892   \n",
       "1           154.0    1.100000  58.897059  ...  96.833333  113.411765   \n",
       "2           154.0    0.333333  67.125000  ...  95.000000  125.687500   \n",
       "3           154.0    0.766667  58.795833  ...  97.250000  116.891892   \n",
       "4           154.0    1.000000  58.795833  ...  97.250000  116.891892   \n",
       "...           ...         ...        ...  ...        ...         ...   \n",
       "3994        145.0    0.900000  68.865385  ...  97.230769  117.230769   \n",
       "3995        117.0    0.840000  58.754774  ...  97.230769  117.820733   \n",
       "3996        145.0    1.125000  74.166667  ...  97.230769  125.666667   \n",
       "3997        145.0    9.650000  92.923077  ...  97.230769  166.615385   \n",
       "3998        145.0    1.116667  57.836957  ...  97.466667  111.532609   \n",
       "\n",
       "           Temp  TroponinI  TroponinT       Urine        WBC      Weight  \\\n",
       "0     37.357143        2.1      0.140  171.052632  10.300000   80.060976   \n",
       "1     36.939130        2.1      0.140  151.560976  11.266667   80.670588   \n",
       "2     37.800000        2.1      0.140  124.951220   4.700000   56.700000   \n",
       "3     36.223077        2.1      0.140  545.833333   9.400000   84.600000   \n",
       "4     36.880000        2.1      0.140   62.131579   4.300000   80.060976   \n",
       "...         ...        ...        ...         ...        ...         ...   \n",
       "3994  37.004762        2.2      0.125   50.769231  14.500000   87.000000   \n",
       "3995  36.580000        2.2      0.125  584.375000   4.733333  166.400000   \n",
       "3996  37.792308        2.2      0.125  116.472222  11.066667  109.000000   \n",
       "3997  38.418182        2.2      0.125   11.230769  13.025000   87.400000   \n",
       "3998  36.381395        2.2      0.125   57.750000   9.228571   87.838889   \n",
       "\n",
       "            pH  In-hospital_death  \n",
       "0     7.387273                  0  \n",
       "1     7.395000                  0  \n",
       "2     7.495000                  0  \n",
       "3     7.387273                  0  \n",
       "4     7.387273                  0  \n",
       "...        ...                ...  \n",
       "3994  7.381429                  0  \n",
       "3995  7.385000                  0  \n",
       "3996  7.396667                  0  \n",
       "3997  7.416000                  1  \n",
       "3998  7.305600                  0  \n",
       "\n",
       "[3999 rows x 43 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "lgbm = LGBMClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier1 = SVC(C = 50, degree = 1, gamma = \"auto\", kernel = \"rbf\", probability = True)\n",
    "\n",
    "# # Initializing Multi-layer perceptron  classifier\n",
    "# classifier2 = MLPClassifier(activation = \"relu\", alpha = 0.1, hidden_layer_sizes = (10,10,10),\n",
    "#                             learning_rate = \"constant\", max_iter = 2000, random_state = 42)\n",
    "\n",
    "# # Initialing Nu Support Vector classifier\n",
    "# classifier3 = NuSVC(degree = 1, kernel = \"rbf\", nu = 0.25, probability = True)\n",
    "\n",
    "# # Initializing Random Forest classifier\n",
    "# classifier4 = RandomForestClassifier(n_estimators = 500, criterion = \"gini\", max_depth = 10,\n",
    "#                                      max_features = \"auto\", min_samples_leaf = 0.005,\n",
    "#                                      min_samples_split = 0.005, n_jobs = -1, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sclf = StackingCVClassifier(classifiers = [classifier1, classifier2, classifier3, classifier4],\n",
    "#                             shuffle = False,\n",
    "#                             use_probas = True,\n",
    "#                             cv = 5,\n",
    "#                             meta_classifier = SVC(probability = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers = {\"SVC\": classifier1,\n",
    "#                \"MLP\": classifier2,\n",
    "#                \"NuSVC\": classifier3,\n",
    "#                \"RF\": classifier4,\n",
    "#                \"Stack\": sclf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in classifiers:\n",
    "#     # Get classifier\n",
    "#     classifier = classifiers[key]\n",
    "    \n",
    "#     # Fit classifier\n",
    "#     classifier.fit(X_train, y_train)\n",
    "        \n",
    "#     # Save fitted classifier\n",
    "#     classifiers[key] = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_classifier = StackingClassifier(classifiers=[lr, rf, gb, xgb, lgbm], meta_classifier=meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:23:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.8546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:23:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.86875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.8765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:23:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.865625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:23:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.863849765258216\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle = True)\n",
    "for train_index, test_index in kfold.split(X_train_scaled, y_train):\n",
    "    X_train_k, X_test_k = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_k, y_test_k = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    stacking_classifier.fit(X_train_k, y_train_k)\n",
    "    y_pred_k = stacking_classifier.predict(X_test_k)\n",
    "    accuracy = accuracy_score(y_test_k, y_pred_k)\n",
    "    print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.87125\n"
     ]
    }
   ],
   "source": [
    "y_pred = stacking_classifier.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy on test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:23:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(classifiers=[LogisticRegression(),\n",
       "                                RandomForestClassifier(random_state=42),\n",
       "                                GradientBoostingClassifier(random_state=42),\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              gamma=None, gpu_id=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learn...\n",
       "                                              max_depth=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=42,\n",
       "                                              reg_alpha=None, reg_lambda=None,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None),\n",
       "                                LGBMClassifier(random_state=42)],\n",
       "                   meta_classifier=LogisticRegression())"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = stacking_classifier.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "Precision: 0.58\n",
      "Recall: 0.21\n",
      "F1 score: 0.31\n"
     ]
    }
   ],
   "source": [
    "y_pred = stacking_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
